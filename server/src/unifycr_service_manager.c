/*
 * Copyright (c) 2017, Lawrence Livermore National Security, LLC.
 * Produced at the Lawrence Livermore National Laboratory.
 *
 * Copyright 2017, UT-Battelle, LLC.
 *
 * LLNL-CODE-741539
 * All rights reserved.
 *
 * This is the license for UnifyCR.
 * For details, see https://github.com/LLNL/UnifyCR.
 * Please read https://github.com/LLNL/UnifyCR/LICENSE for full license text.
 */

/*
 * Copyright (c) 2017, Lawrence Livermore National Security, LLC.
 * Produced at the Lawrence Livermore National Laboratory.
 * Copyright (c) 2017, Florida State University. Contributions from
 * the Computer Architecture and Systems Research Laboratory (CASTL)
 * at the Department of Computer Science.
 *
 * Written by: Teng Wang, Adam Moody, Weikuan Yu, Kento Sato, Kathryn Mohror
 * LLNL-CODE-728877. All rights reserved.
 *
 * This file is part of burstfs.
 * For details, see https://github.com/llnl/burstfs
 * Please read https://github.com/llnl/burstfs/LICENSE for full license text.
 */

#include <aio.h>
#include <time.h>
#include <mpi.h>

#include "unifycr_global.h"

/* The service manager thread runs in a loop waiting for incoming
 * requests.  When it receives a message, it unpacks all read
 * requests and appends them to the service_msgs list.  It delays
 * for some time in acting on requests in the hopes of buffering
 * read bursts to make I/O more efficient.  If no read request
 * has come in, and the delay time out has expired, and there are
 * pening read requests to service, then it services all requests.
 *
 * It first creates a set of read tasks based on the set of read
 * requests.  The read requests are sorted by source file and then
 * by offset, and read requests that refer to contiguous data
 * regions are merged into a large read task.  Read tasks are
 * added to a read_task list.
 *
 * The read tasks are executed to copy data into a read buffer.
 * Data that is copied from shared memory simply uses memcpy().
 * Data that spans shared memory and the spillover file uses
 * memcpy with pread.  Data that is fully in the spillover file
 * are read with async I/O (aio) operations.  The aio operations
 * are added to a pending_reads queue that is later waited on.
 *
 * After all data has been read, results are packed into send
 * buffers.  This is done by matching read tasks with corresponding
 * read requests.  When send buffers are filled with read replies
 * (acks), they are sent back to requesting delegators with
 * MPI_Isend calls.  The MPI_Request objects for those isends are
 * added to a pending_sends list, which is later waited on.
 *
 * After replying to all service_msgs, the service manager
 * thread again starts listening for more incoming requests */

/* records info needed to build read reply to send back to
 * requesting delegator, these are appened in an ack list
 * which records a set of read replies before being sent */
typedef struct {
    recv_msg_t msg; /* header information for read reply */
    char* addr;     /* address of data in read buffer */
} ack_meta_t;

/* this records info about outstanding sends to delegators,
 * including the MPI request that must be waited on to
 * determine when send has completed, these are added to
 * an pending sends list when sent and then iterated over
 * while waiting for all pending sends to complete */
typedef struct {
    MPI_Request req; /* MPI request for outstanding isend */
    MPI_Status stat; /* status for test call */
    int src_rank;    /* target delegator rank */
    int src_thrd;    /* target delegator thread */
} ack_stat_t;

/* records info about read tasks, which are generated by
 * unpacking incoming read requests from remote delegators,
 * it encodes information about a range of read requests
 * that generated the read task, read requests that refer
 * to contiguous data may be merged into a single read task,
 * and the app_id and client_id are used to determine
 * the memory/files holding the source data */
typedef struct {
    size_t size;      /* size of read operation */
    int start_idx;    /* index of starting read request */
    int end_idx;      /* index of ending read request */
    int app_id;       /* app id holding requested data */
    int cli_id;       /* client id holding requested data */
    int arrival_time; /* time stamp when read request arrived */
} read_task_t;

/* defines an array of read tasks */
typedef struct {
    read_task_t* read_tasks; /* list of read tasks */
    int num;                 /* number of active read tasks */
    int cap;                 /* total capacity of read task list */
} task_set_t;

/* defines an array of read requests, generated by unpacking
 * read requests from requesting delegators */
typedef struct {
    send_msg_t* msg; /* buffer of read requests */
    int num;         /* number of active read requests in buffer */
    int cap;         /* total capacity of read request list */
} service_msgs_t;

/* tracks an outstanding read operation, these are generated
 * from read tasks and added to a list of pending read operations,
 * which are later waited on before sending data back to requesting
 * delegators */
typedef struct {
    int err_submit;       /* indicates whether read was submitted */
    struct aiocb read_cb; /* structure for outstanding aio read */
    int index;            /* index in read task list for this read */
    int start_pos;        /* starting byte offset into read request */
    int end_pos;          /* ending byte offset into read request */
    char* mem_pos;        /* buffer holding read data */
} pended_read_t;

/* defines a list of read replies to be sent to a delegator */
typedef struct {
    arraylist_t* ack_list; /* list of read replies for delegator */
    int rank_id;           /* rank of remote delegator to send to */
    int thrd_id;           /* thread id of remote delegator */
    int src_cli_rank;      /* rank of client that initiated read */
    size_t src_sz;         /* total data size in read replies */
    int start_cursor;      /* offset within ack_list */
} rank_ack_meta_t;

/* defines an list of reply data for different delegators,
 * list is ordered by (rank,thread) of delegator for fast lookup */
typedef struct {
    rank_ack_meta_t* ack_metas; /* read reply data for a delegator */
    int num;                    /* number of items in list */
} rank_ack_task_t;

/* records list of read requests from requesting delegators */
static service_msgs_t service_msgs;

/* list of read tasks that must be executed,
 * generated from read requests */
static task_set_t read_task_set;

/* list of read reply data for each delegator */
static rank_ack_task_t rank_ack_task;

/* list of outstanding read operations */
static arraylist_t* pended_reads;

/* list of outstanding send operations */
static arraylist_t* pended_sends;

/* list of buffers to be used in send operations */
static arraylist_t* send_buf_list;

/* counter for time waited before creating read tasks,
 * used to buffer multiple read requests before responding
 * with the idea that reads come in bursts */
static int wait_time = 0;

/* tracks running total of bytes in current read burst */
static long burst_data_sz = 0;

/* this will point to a buffer to hold read data while gathering it
 * from source memory/files and before being packed into send buffers
 * for sending read replies */
static char* read_buf;

/* sort read requests into log files by
 * app id, then client id, then log offset */
static int compare_send_msg(const void* a, const void* b)
{
    const send_msg_t* ptr_a = a;
    const send_msg_t* ptr_b = b;

    if (ptr_a->dest_app_id > ptr_b->dest_app_id) {
        return 1;
    }

    if (ptr_a->dest_app_id < ptr_b->dest_app_id) {
        return -1;
    }

    if (ptr_a->dest_client_id > ptr_b->dest_client_id) {
        return 1;
    }

    if (ptr_a->dest_client_id < ptr_b->dest_client_id) {
        return -1;
    }

    if (ptr_a->dest_offset > ptr_b->dest_offset) {
        return 1;
    }

    if (ptr_a->dest_offset < ptr_b->dest_offset) {
        return -1;
    }

    return 0;
}

/* starts a new read task based on read request in service_msgs
 * at given index */
static void reset_read_tasks(task_set_t* read_task_set,
                             service_msgs_t* service_msgs, int index)
{
    /* get pointer to service message at given index */
    send_msg_t* msg = &service_msgs->msg[index];

    /* get pointer to current read task */
    int idx = read_task_set->num;
    read_task_t* read_task = &read_task_set->read_tasks[idx];

    /* copy fields from message to read task */
    read_task->start_idx    = index;
    read_task->end_idx      = index;
    read_task->size         = msg->length;
    read_task->app_id       = msg->dest_app_id;
    read_task->cli_id       = msg->dest_client_id;
    read_task->arrival_time = msg->arrival_time;
}

/**
* Cluster read requests based on file
* offset and ages; Each log file is uniquely
* identified by client-side app_id and client_id, so
* from these two, we can locate the target
* log file (generated by the client-side program).
* @param: service_msgs: a list of received messages
* @param: read_task_set: a list of read tasks containing
* the clustered read requests
* return success/error
*/
static int sm_cluster_reads(task_set_t* read_task_set,
                            service_msgs_t* service_msgs)
{
    /* sort service messages by log file (app_id, client_id)
     * and then by offset within each log file */
    qsort(service_msgs->msg, service_msgs->num,
          sizeof(send_msg_t), compare_send_msg);

    /* initialize count of read tasks */
    read_task_set->num = 0;

    /* create read task given first service message */
    reset_read_tasks(read_task_set, service_msgs, 0);
    read_task_set->num++;

    /* iterate over each service message and create read tasks,
     * will merge multiple read requests into read tasks
     * when two requests refer to contiguous data in a log file */
    int i;
    for (i = 1; i < service_msgs->num; i++) {
        /* get pointer to current service message */
        send_msg_t* msg = &service_msgs->msg[i];

        /* get pointer to preivous read task */
        read_task_t* last_read =
            &read_task_set->read_tasks[read_task_set->num - 1];

        /* check whether current message reads from the same log file,
         * as our last read task */
        if ((last_read->app_id != msg->dest_app_id) ||
            (last_read->cli_id != msg->dest_client_id)) {
            /* reading on a different local log file,
             * so create a new read task for this message */
            reset_read_tasks(read_task_set, service_msgs, i);
            read_task_set->num++;
        } else {
            /* this message reads from the same log file as our last
             * read request */

            /* get pointer to previous read request */
            send_msg_t* last_msg = &service_msgs->msg[i - 1];

            /* see if we can tack current message on to
             * previous read request */
            size_t last_offset = last_msg->dest_offset + last_msg->length;
            if (last_offset == msg->dest_offset) {
                /* current message starts where last read request
                 * ends, so append it to last read request if no larger
                 * than read_block_size */

                /* the size of individual read should be smaller
                 * than read_block_size, if read size is larger it
                 * needs to be split into the unit of READ_BLOCK_SIZE */
                if ((last_read->size + msg->length) <= READ_BLOCK_SIZE) {
                    /* tack current message on previous read request */
                    last_read->end_idx = i;
                    last_read->size += msg->length;

                    /* update minimum arrival time */
                    if (msg->arrival_time < last_read->arrival_time) {
                        last_read->arrival_time = msg->arrival_time;
                    }
                } else {
                    /* if larger than read block size, start a new
                     * read task, here the data size requested by
                     * individual read request should be smaller
                     * than read_block_size. The larger one
                     * has already been split by the initiator */
                    reset_read_tasks(read_task_set, service_msgs, i);
                    read_task_set->num++;
                }
            } else {
                /* not contiguous from the last offset,
                 * start a new read request */
                reset_read_tasks(read_task_set, service_msgs, i);
                read_task_set->num++;
            }
        }
    }

    return UNIFYCR_SUCCESS;
}

/* compare by rank and then thread in increasing order */
static int compare_rank_thrd(int src_rank, int src_thrd,
                             int cmp_rank, int cmp_thrd)
{
    if (src_rank > cmp_rank) {
        return 1;
    }
    if (src_rank < cmp_rank) {
        return -1;
    }
    if (src_thrd > cmp_thrd) {
        return 1;
    }
    if (src_thrd < cmp_thrd) {
        return -1;
    }
    return 0;
}

/* returns index where delegator (rank,thread),
 * should be in list, caller must check whether
 * delegator at that position matches */
static int find_ack_meta(
    rank_ack_task_t* rank_ack_task,
    int src_rank,
    int src_thrd,
    int* found)
{
    /* assume we won't find item */
    *found = 0;

    /* if nothing in list, place this as first item */
    if (rank_ack_task->num == 0) {
        return 0;
    }

    rank_ack_meta_t* metas = rank_ack_task->ack_metas;

    /* if list has one item, compare to that item */
    if (rank_ack_task->num == 1) {
        /* compare to first item */
        int cmp = compare_rank_thrd(src_rank, src_thrd,
                                    metas[0].rank_id, metas[0].thrd_id);
        if (cmp < 0) {
            /* item is smaller than first element */
            return 0;
        } else if (cmp > 0) {
            /* item is smaller than first element */
            return 1;
        } else {
            /* item matches first element */
            *found = 1;
            return 0;
        }
    }

    /* execute binary search for item location in list */
    int left  = 0;
    int right = rank_ack_task->num - 1;
    int mid   = (left + right) / 2;
    while (right > left + 1) {
        /* compare item to middle element */
        int cmp = compare_rank_thrd(src_rank, src_thrd,
                                    metas[mid].rank_id, metas[mid].thrd_id);
        if (cmp > 0) {
            /* item is larger than middle item,
             * so bump left range up */
            left = mid;
        } else if (cmp < 0) {
            /* item is smaller than middle item,
             * so move right down to middle */
            right = mid;
        } else {
            /* found an exact match with middle element */
            *found = 1;
            return mid;
        }

        /* update middle */
        mid = (left + right) / 2;
    }

    /* two elements left in the list, compare to left element */
    int cmp_left = compare_rank_thrd(src_rank, src_thrd,
                                     metas[left].rank_id, metas[left].thrd_id);
    if (cmp_left < 0) {
        /* item should come before left element */
        return left;
    } else if (cmp_left == 0) {
        /* item matches left item */
        *found = 1;
        return left;
    }

    /* item is larger than left element, so compare to right */
    int cmp_right = compare_rank_thrd(src_rank, src_thrd,
        metas[right].rank_id, metas[right].thrd_id);
    if (cmp_right < 0) {
        /* item should come before right element */
        return right;
    } else if (cmp_right == 0) {
        /* item matches right element */
        *found = 1;
        return right;
    }

    /* otherwise, item must be larger than right element */
    return (right + 1);
}

/* insert read reply list for specified (rank_id, thrd_id) delegator
 * into ack list, keep ordered by rank,thread for fast lookup */
static int insert_ack_meta(
    rank_ack_task_t* rank_ack_task,
    ack_meta_t* ack,
    int pos,
    int rank_id,
    int thrd_id,
    int src_cli_rank)
{
    /* get pointer to array of read reply data for delegators */
    rank_ack_meta_t* metas = rank_ack_task->ack_metas;

    /* check whether insert location is in middle of the list */
    if (pos < rank_ack_task->num) {
        /* need to insert in the middle, bump all entries
         * past pos up a slot */
        int i;
        for (i = rank_ack_task->num - 1; i >= pos; i--) {
            metas[i + 1] = metas[i];
        }
    }

    /* get pointer to ack meta data structure */
    rank_ack_meta_t* ack_meta = &metas[pos];

    /* initialize with values */
    ack_meta->ack_list     = arraylist_create();
    ack_meta->rank_id      = rank_id;
    ack_meta->thrd_id      = thrd_id;
    ack_meta->src_cli_rank = src_cli_rank;
    ack_meta->src_sz       = ack->msg.length;
    ack_meta->start_cursor = 0;

    /* check that we were able to create a new ack_list */
    if (ack_meta->ack_list == NULL) {
        return (int)UNIFYCR_ERROR_NOMEM;
    }

    /* insert ack_meta into our list */
    arraylist_add(ack_meta->ack_list, ack);

    /* increment the number of entries in our list */
    rank_ack_task->num++;

    return UNIFYCR_SUCCESS;
}

/* send back ack to the remote delegator
 * packs read replies into a send buffer, sends data with isend,
 * adds record of send to pending sends list */
static int sm_ack_remote_delegator(rank_ack_meta_t* ack_meta)
{
    int i;

    /* allocate more send buffers if we're at capacity */
    if (send_buf_list->size == send_buf_list->cap) {
        /* at capacity in our list, allocate more space,
         * double capacity in array */
        size_t new_cap = 2 * send_buf_list->cap;
        send_buf_list->elems = (void**)realloc(send_buf_list->elems,
                                               new_cap * sizeof(void*));

        /* intialize pointers in new portion of array */
        for (i = send_buf_list->cap; i < new_cap; i++) {
            send_buf_list->elems[i] = NULL;
        }

        /* record new capacity */
        send_buf_list->cap = new_cap;
    }

    /* attempt to reuse allocated buffer if we can */
    if (send_buf_list->elems[send_buf_list->size] == NULL) {
        /* need to allocate a new buffer */
        send_buf_list->elems[send_buf_list->size] =
            malloc(SENDRECV_BUF_LEN);
    }

    /* get pointer to send buffer */
    char* send_msg_buf = send_buf_list->elems[send_buf_list->size];
    send_buf_list->size++;

    /* running total number of bytes we'll send */
    int send_sz = 0;

    /* compute number of read replies we'll send */
    size_t ack_count = arraylist_size(ack_meta->ack_list);
    size_t ack_start = ack_meta->start_cursor;
    int len = ack_count - ack_start;

    /* copy in number of read replies to message */
    memcpy(send_msg_buf + send_sz, &len, sizeof(int));
    send_sz += sizeof(int);

    /* pack read replies into send buffer */
    for (i = ack_start; i < ack_count; i++) {
        /* get pointer to read reply header */
        ack_meta_t* meta =
            (ack_meta_t*)arraylist_get(ack_meta->ack_list, i);

        /* copy read reply header to send buffer */
        memcpy(send_msg_buf + send_sz, &(meta->msg), sizeof(recv_msg_t));
        send_sz += sizeof(recv_msg_t);

        /* copy file data to send buffer */
        size_t length = (size_t) meta->msg.length;
        memcpy(send_msg_buf + send_sz, meta->addr, length);
        send_sz += (int) length;
    }

    /* get rank and thread id of remote delegator */
    int del_rank   = ack_meta->rank_id;
    int del_thread = ack_meta->thrd_id;

    /* allocate a new ack stat structure to track details
     * of pending send */
    ack_stat_t* ack_stat = (ack_stat_t*)malloc(sizeof(ack_stat_t));
    ack_stat->src_rank = del_rank;
    ack_stat->src_thrd = del_thread;

    /* send read replies to delegator (rank and thread),
     * record MPI request in ack stat structure to wait later */
    MPI_Isend(send_msg_buf, send_sz, MPI_BYTE,
              del_rank, SER_DATA_TAG + del_thread,
              MPI_COMM_WORLD, &(ack_stat->req));

    /* add item to our list of pending sends */
    arraylist_add(pended_sends, ack_stat);

    return UNIFYCR_SUCCESS;
}

/*
 * insert a message to an entry of ack (read reply) list corresponding
 * to its destination delegator.
 *
 * @param: rank_ack_task: a list of ack for each (rank, thrd) pair
 * @param: mem_addr: address of data to be acked in mem_pool
 * @param service_msgs and index: identifies msg to be inserted
 *  to ack_lst
 * @param src_offset: offset of the requested segment on the logical
 *  file (not the physical log file on SSD.
 *  E.g. for N-1 pattern, logical
 *  offset is the offset on the shared file)
 * @param len: length of the message
 * */
static int insert_to_ack_list(
    rank_ack_task_t* rank_ack_task,
    char* mem_addr,
    service_msgs_t* service_msgs,
    int index,
    size_t src_offset,
    size_t len,
    int errcode)
{
    int rc = 0;

    /* get pointer to read request we are replying to */
    send_msg_t* msg = &service_msgs->msg[index];

    /* allocate a new structure to record ack meta data */
    ack_meta_t* ack = (ack_meta_t*)malloc(sizeof(ack_meta_t));

    /* the src_offset might start from any position in the message, so
     * make it a separate parameter */
    ack->msg.src_fid    = msg->src_fid; /* global file id */
    ack->msg.src_offset = src_offset;   /* offset in file */
    ack->msg.length     = len;          /* length of data */
    ack->msg.errcode    = errcode;      /* error code for read (pass/fail) */
    ack->addr           = mem_addr;     /* pointer to data in read buffer */

    /* after setting the ack for this message, link it
     * to a ack list based on its destination. */

    int src_rank     = msg->src_delegator_rank;
    int src_thrd     = msg->src_thrd;
    int src_cli_rank = msg->src_dbg_rank;

    /* find the position in the list for target delegator */
    int found = 0;
    int pos = find_ack_meta(rank_ack_task, src_rank, src_thrd, &found);

    /* check whether delegator at this position is the target */
    if (! found) {
        /* it's not, so insert new entry for the target into the
         * list at this position */
        rc = insert_ack_meta(rank_ack_task, ack, pos,
                             src_rank, src_thrd, src_cli_rank);
    } else {
        /* found the corresponding entry for target delegator */
        rank_ack_meta_t* ack_meta = &rank_ack_task->ack_metas[pos];

        /* compute number of read replies waiting to be sent */
        int num_entries = arraylist_size(ack_meta->ack_list);
        int num_to_ack = num_entries - ack_meta->start_cursor;

        /* number of bytes needed to pack existing read replies */
        size_t curr_bytes = (num_to_ack * sizeof(ack_meta_t)) +
                            ack_meta->src_sz;

        /* number of bytes to pack this read reply */
        size_t bytes = sizeof(ack_meta_t) + ack->msg.length;

        /* check whether we can fit this data into the
         * existing send block */
        if (curr_bytes + bytes > SENDRECV_BUF_LEN) {
            /* not enough room, send the current list of read replies */
            rc = sm_ack_remote_delegator(ack_meta);

            /* start a new list */
            ack_meta->src_sz = ack->msg.length;
            arraylist_add(ack_meta->ack_list, ack);

            /* start_cursor records the starting ack
             * for the next send */
            ack_meta->start_cursor += num_to_ack;

            /* check that our reads and sends completed ok */
            if (rc < 0) {
                return (int)UNIFYCR_ERROR_SEND;
            }
        } else {
            /* current read reply fits in send buffer,
             * add it to the list */
            ack_meta->src_sz += ack->msg.length;
            arraylist_add(ack_meta->ack_list, ack);
        }
    }

    return UNIFYCR_SUCCESS;
}

/* insert the data read for each element in read task list to read
 * reply list, data will be sent later */
static int batch_insert_to_ack_list(
    rank_ack_task_t* rank_ack_task, /* read reply list for delegator */
    read_task_t* read_task,         /* data returned from read task */
    service_msgs_t* service_msgs,   /* read requests */
    char* mem_addr,                 /* memory loc to copy read data */
    int start_offset,               /* first offset in read task */
    int end_offset,                 /* last offset in read task */
    int errcode)                    /* error code on read (pass/fail) */
{
    /* search for the starting read request in service msgs for
     * a given region of read_task_t identified by start_offset
     * and size of read task */

    /*                          read_task
     *                      start_offset       end_offset
     *    read_task_t: -----------******************------------
     *    service_msgs:[    ],[*********],[***], [******],[      ]
     *
     * */

    /* find index in read requests such that it contains starting
     * offset for read task */
    int idx = read_task->start_idx;
    int cur_offset = 0;
    while (1) {
        /* get pointer to current read request */
        send_msg_t* msg = &service_msgs->msg[idx];

        /* check whether end offset of this read request comes
         * at or after starting offset of read task */
        if (cur_offset + msg->length >= start_offset) {
            /* starting offset of read task falls between start
             * and end offset of this read request */
            break;
        }

        /* move on to next read request */
        cur_offset += msg->length;
        idx++;
    }

    /* compute leading bytes in read request that this read task
     * does not overlap with */
    int skip_offset = start_offset - cur_offset;

    /* insert read replies for leading read request and all middle
     * read requests */
    int first = 1;
    int mem_pos = 0;
    while (1) {
        /* get pointer to read request */
        send_msg_t* msg = &service_msgs->msg[idx];

        /* stop if we reached the read request that contains the last
         * byte of our read task */
        if (cur_offset + msg->length >= end_offset + 1) {
            /* ending byte in read task comes before ending byte
             * in read request */
            break;
        }

        /* compute length and offset of read request that we cover with
         * this read task, assume it's the whole read request */
        long length = msg->length;
        long offset = msg->src_offset;
        if (first == 1) {
            /* in the first read request, the read task may start
             * partway through, so skip any leading bytes */
            length = msg->length - skip_offset;
            offset = msg->src_offset + skip_offset;
            first = 0;
        }

        /* add entry to read reply list */
        insert_to_ack_list(rank_ack_task, mem_addr + mem_pos,
                           service_msgs, idx, offset, length, errcode);

        /* update our offset into read reply buffer */
        mem_pos += length;

        /* update offset into read task data */
        cur_offset += length;

        /* move on to next read request */
        idx++;
    }

    /* the read task may not fully fill the ending read request */
    if (mem_pos < end_offset - start_offset + 1) {
        /* compute remaining length of read task */
        long length = (end_offset - start_offset + 1) - mem_pos;

        /* starting offset for read request */
        long offset = service_msgs->msg[idx].src_offset;

        /* add entry to read reply list */
        insert_to_ack_list(rank_ack_task, mem_addr + mem_pos,
                           service_msgs, idx, offset, length, errcode);
    }

    return UNIFYCR_SUCCESS;
}

/**
* Wait until all data are read and sent
* @param: read_task_set: a list of reading task
* @param: service_msgs: a list of received read requests
* @param: a list of send tasks for acknowledging the
* requesting delegators
* return success/error
*/
static int sm_wait_until_digested(task_set_t* read_task_set,
                                  service_msgs_t* service_msgs,
                                  rank_ack_task_t* read_ack_task)
{
    int i;

    /* pointer to array of boolean flags for whether we need to test
     * outstanding operations */
    int* flags = NULL;

    /* get number of pending read operations */
    int num_pended_reads = arraylist_size(pended_reads);
    if (num_pended_reads > 0) {
        /* allocate space for pending flags */
        size_t flags_size = num_pended_reads * sizeof(int);
        flags = (int*)malloc(flags_size);

        /* set all flags to 0 */
        memset(flags, 0, flags_size);
    }

    /* wait for all pending read operations to complete */
    long counter = 0;
    while (1) {
        /* check whether we have processed all reads */
        if (counter == num_pended_reads) {
            break;
        }

        /* iterate over pending reads */
        for (i = 0; i < num_pended_reads; i++) {
            /* get meta data for this pending read */
            pended_read_t* pendread =
                (pended_read_t*)arraylist_get(pended_reads, i);

            /* don't need to check if we failed to even submit
             * the read operation */
            if (flags[i] != 1 && pendread->err_submit) {
                /* mark that this read operation has completed */
                flags[i] = 1;
                counter++;

                /* failed to submit, so we failed to read */
                int errcode = (int)UNIFYCR_ERROR_READ;

                /* add read reply to ack_list as failed */
                batch_insert_to_ack_list(read_ack_task,
                    &read_task_set->read_tasks[pendread->index],
                    service_msgs,
                    pendread->mem_pos,
                    pendread->start_pos,
                    pendread->end_pos,
                    errcode);

                continue;
            }

            /* check whether this read has completed */
            if (flags[i] != 1 &&
                    aio_error(&pendread->read_cb) != EINPROGRESS) {
                /* mark that this read operation has completed */
                flags[i] = 1;
                counter++;

                /* assume that we succeeded */
                int errcode = UNIFYCR_SUCCESS;

                /* get return code for read operation */
                ssize_t ret_code = aio_return(&pendread->read_cb);

                /* check that read completed without error */
                if (ret_code != (ssize_t)pendread->read_cb.aio_nbytes) {
                    /* read error or short read,
                     * consider either case as a read error */
                    errcode = (int)UNIFYCR_ERROR_READ;
                }

                /* add read reply to ack_list */
                batch_insert_to_ack_list(read_ack_task,
                    &read_task_set->read_tasks[pendread->index],
                    service_msgs,
                    pendread->mem_pos,
                    pendread->start_pos,
                    pendread->end_pos,
                    errcode);
            }
        }
    }

    /* free flags array */
    if (flags != NULL) {
        free(flags);
        flags = NULL;
    }

    /* reset our list of pending read operations */
    arraylist_reset(pended_reads);

    /* read operations have completed,
     * send data to delegators */

    /* iterate over list of delegators and send remaining acks */
    for (i = 0; i < read_ack_task->num; i++) {
        /* get data structure for this delegator */
        rank_ack_meta_t* ack_meta = &read_ack_task->ack_metas[i];

        /* get total number of read replies in this list */
        long tmp_sz = arraylist_size(ack_meta->ack_list);

        /* if we have read replies we have yet to send,
         * send them now */
        if (ack_meta->start_cursor < tmp_sz) {
            /* got some read replies, send them */
            int ret_code = sm_ack_remote_delegator(ack_meta);
            if (ret_code != UNIFYCR_SUCCESS) {
                return ret_code;
            }
        }
    }

    /* sends issued, now wait for them to complete */

    /* get number of outstanding sends
     * initiated in sm_ack_remote_delegator */
    int num_pended_sends = arraylist_size(pended_sends);
    if (num_pended_sends > 0) {
        /* got some outstandings sends, allocate space for flags */
        size_t flags_size = num_pended_sends * sizeof(int);
        flags = (int*)malloc(flags_size);

        /* set all flags to 0 */
        memset(flags, 0, flags_size);
    }

    /* wait until all acks are sent */
    counter = 0;
    while (1) {
        /* check whether we have waited on all sends */
        if (counter == num_pended_sends) {
            break;
        }

        /* iterate over each send we issued */
        for (i = 0; i < num_pended_sends; i++) {
            /* if send is still outstanding, check whether it's done */
            if (flags[i] == 0) {
                /* still outstanding, get data for this send */
                ack_stat_t* ack_stat = arraylist_get(pended_sends, i);

                /* test whether send is complete */
                int ret_code = MPI_Test(&ack_stat->req, &flags[i],
                                        &ack_stat->stat);
                if (ret_code != MPI_SUCCESS) {
                    return (int)UNIFYCR_ERROR_RECV;
                }

                /* if send completed, bump our counter */
                if (flags[i] != 0) {
                    counter++;
                }
            }
        }
    }

    /* free flags array */
    if (flags != NULL) {
        free(flags);
        flags = NULL;
    }

    /* clear our list of sends */
    arraylist_reset(pended_sends);

    /* reset our list of read replies */
    for (i = 0; i < read_ack_task->num; i++) {
        rank_ack_meta_t* ack_meta = &(read_ack_task->ack_metas[i]);

        arraylist_reset(ack_meta->ack_list);
        ack_meta->rank_id      = -1;
        ack_meta->thrd_id      = -1;
        ack_meta->src_sz       = 0;
        ack_meta->start_cursor = 0;
    }
    read_ack_task->num = 0;

    /* TODO: might be nice to free some send buffers here */

    /* set active send buffers back to 0,
     * we do not free send buffers so that we do not have to
     * allocate them again */
    send_buf_list->size = 0;

    return UNIFYCR_SUCCESS;
}

static int compare_read_task(const void* a, const void* b)
{
    const read_task_t* ptr_a = a;
    const read_task_t* ptr_b = b;

    if (ptr_a->size > ptr_b->size) {
        return 1;
    }

    if (ptr_a->size < ptr_b->size) {
        return -1;
    }

    if (ptr_a->arrival_time > ptr_b->arrival_time) {
        return 1;
    }

    if (ptr_a->arrival_time < ptr_b->arrival_time) {
        return -1;
    }

    return 0;
}

/**
* Read and send the data via pipelined read, copy and send
* @param: read_task_set: a list of reading task
* @param: service_msgs: a list of received read requests
* @param: a list of send tasks for acknowledging the
* requesting delegators
* return success/error
*/
static int sm_read_send_pipe(task_set_t* read_task_set,
                             service_msgs_t* service_msgs,
                             rank_ack_task_t* rank_ack_task)
{
    /* sort read tasks by size and then by arrival time */
    qsort(read_task_set->read_tasks, read_task_set->num,
          sizeof(read_task_t), compare_read_task);

    /* points to offset in read reply buffer */
    long buf_cursor = 0;

    /* iterate over read tasks and pack read replies into send buffer */
    int i;
    for (i = 0; i < read_task_set->num; i++) {
        /* get pointer to current read task */
        read_task_t* read_task = &read_task_set->read_tasks[i];

        /* get size of data we are to read */
        size_t size = read_task->size;

        /* check whether we have room in the read buffer to hold data */
        if ((buf_cursor + size) > READ_BUF_SZ) {
            /* no room, wait until reads complete and send
             * out replies */
            sm_wait_until_digested(read_task_set,
                                   service_msgs, rank_ack_task);

            /* reset to start of read buffer */
            buf_cursor = 0;
        }

        /* get app id and client id for this read task,
         * defines log files holding data */
        int app_id = read_task->app_id;
        int cli_id = read_task->cli_id;

        /* look up app config for given app id */
        app_config_t* app_config =
            arraylist_get(app_config_list, app_id);
        assert(app_config);

        /* get index of starting service message */
        int start_idx = read_task->start_idx;

        /* get offset in log file */
        send_msg_t* msg = &service_msgs->msg[start_idx];
        size_t offset = msg->dest_offset;

        /* prepare read opertions based on data location */
        if ((offset + read_task->size) <= app_config->data_size) {
            /* requested data in read_task is totally in shared memory,
             * get pointer to position in shared memory */
            char* log_ptr = app_config->shm_superblocks[cli_id] +
                            app_config->data_offset + offset;

            /* copy data into read reply buffer */
            char* buf_ptr = read_buf + buf_cursor;
            memcpy(buf_ptr, log_ptr, size);
            buf_cursor += size;

            /* we assume memcpy worked */
            int errcode = UNIFYCR_SUCCESS;

            /* prepare read reply meta data */
            batch_insert_to_ack_list(rank_ack_task, read_task,
                service_msgs, buf_ptr, 0, size - 1, errcode);
        } else if (offset < app_config->data_size) {
            /* part of the requested data is in shared memory,
             * compute size in shared memory */
            long sz_from_mem = app_config->data_size - offset;

            /* get pointer to position in shared memory */
            char* log_ptr = app_config->shm_superblocks[cli_id] +
                            app_config->data_offset + offset;

            /* copy data into read reply buffer */
            char* buf_ptr = read_buf + buf_cursor;
            memcpy(buf_ptr, log_ptr, sz_from_mem);
            buf_cursor += sz_from_mem;

            /* we assume memcpy worked */
            int errcode = UNIFYCR_SUCCESS;

            /* compute size in spillover file */
            long sz_from_ssd = size - sz_from_mem;

            /* read data from spillover file */
            int fd = app_config->spill_log_fds[cli_id];
            ssize_t nread = pread(fd, read_buf + buf_cursor,
                                  sz_from_ssd, 0);
            if (nread != (ssize_t)sz_from_ssd) {
                /* read error or short read,
                 * consider either case to be an error */
                errcode = (int)UNIFYCR_ERROR_READ;
            }
            buf_cursor += sz_from_ssd;

            /* prepare read reply meta data */
            batch_insert_to_ack_list(rank_ack_task, read_task,
                service_msgs, buf_ptr, 0, size - 1, errcode);
        } else {
            /* all requested data in the current read task
             * are in spillover files */
            int fd = app_config->spill_log_fds[cli_id];

            /* allocate empty pending read structure */
            pended_read_t* ptr =
                (pended_read_t*)malloc(sizeof(pended_read_t));

            /* fill in aio fields */
            memset(&ptr->read_cb, 0, sizeof(struct aiocb));
            ptr->read_cb.aio_fildes = fd;
            ptr->read_cb.aio_buf    = read_buf + buf_cursor;
            ptr->read_cb.aio_offset = offset - app_config->data_size;
            ptr->read_cb.aio_nbytes = size;

            /* index of read task for this pending read */
            ptr->index = i;

            /* offset locations in generating read request */
            ptr->start_pos = 0;
            ptr->end_pos   = size - 1;

            /* send buffer location to copy data when complete */
            ptr->mem_pos = read_buf + buf_cursor;

            /* submit read as aio operation */
            ptr->err_submit = 0;
            int rc = aio_read(&ptr->read_cb);
            if (rc < 0) {
                /* remember that we failed to submit this read */
                ptr->err_submit = 1;
            }
            buf_cursor += size;

            /* enqueue entry in our list of pending reads */
            arraylist_add(pended_reads, ptr);
        }

        /* update accounting for burst size */
        burst_data_sz += size;
    }

    /* have initiated all read tasks, wait for them to finish
     * and send results to delegators */
    sm_wait_until_digested(read_task_set, service_msgs, rank_ack_task);

    return UNIFYCR_SUCCESS;
}

/**
* decode the message received from request_manager
* @param receive buffer that contains the requests
* @return success/error code
*/
static int sm_decode_msg(char* recv_msg_buf)
{
    /* get pointer to start of receive buffer */
    char* ptr = recv_msg_buf;

    /* advance past command */
    ptr += sizeof(int);

    /* extract number of read requests in message */
    int num = *((int*)ptr);
    ptr += sizeof(int);

    LOGDBG("decoding %d requests", num);

    /* get pointer to read request */
    send_msg_t* msg = (send_msg_t*)ptr;

    /* allocate a larger array of service requests if needed */
    if (num + service_msgs.num >= service_msgs.cap) {
        /* get a larger buffer (2x what is currently needed) */
        size_t count = 2 * (num + service_msgs.num);

        /* allocate larger buffer (2x what is currently needed) */
        size_t bytes = count * sizeof(send_msg_t);
        service_msgs.msg =
            (send_msg_t*)realloc(service_msgs.msg, bytes);
        if (service_msgs.msg == NULL) {
            /* failed to allocate memory */
            return (int)UNIFYCR_ERROR_NOMEM;
        }

        /* got the memory, increase the capacity */
        service_msgs.cap = count;

        /* allocate corresponding space for read tasks */
        bytes = count * sizeof(read_task_t);
        read_task_set.read_tasks =
            (read_task_t*)realloc(read_task_set.read_tasks, bytes);
        if (read_task_set.read_tasks == NULL) {
            /* failed to allocate memory */
            return (int)UNIFYCR_ERROR_NOMEM;
        }

        /* got the memory, increase the capacity */
        read_task_set.cap = count;
    }

    /* get current timestamp as integer */
    int now = (int)time(NULL);

    /* unpack read requests to fill in service messages */
    int iter;
    for (iter = 0; iter < num; iter++) {
        /* copy values from read request */
        service_msgs.msg[service_msgs.num] = msg[iter];

        /* set time stamp on when we received this request */
        service_msgs.msg[service_msgs.num].arrival_time = now;

        /* increment the number of service requests
         * and go to next read request */
        service_msgs.num++;
    }

    return UNIFYCR_SUCCESS;
}

/* clean up state and resources allocated by service manager thread
 * before shutting down */
static int sm_exit()
{
    int rc = UNIFYCR_SUCCESS;

    arraylist_free(pended_reads);
    arraylist_free(pended_sends);
    arraylist_free(send_buf_list);

    free(service_msgs.msg);
    free(read_task_set.read_tasks);

    int i;
    for (i = 0; i < rank_ack_task.num; i++) {
        arraylist_free(rank_ack_task.ack_metas[i].ack_list);
    }

    return rc;
}

/* return code for service manager thread,
 * this is global since we return its address
 * from the pthread entry point function */
int sm_rc;

/* entry point for the service thread, service the read requests
 * received from the requesting delegators, executes a loop constantly
 * waiting on incoming message, for each message that comes in,
 * appends read requests to service_msgs list, if no message has
 * arrived, and after some wait time (to catch bursty reads),
 * then convert read requests into read tasks, execute read tasks
 * to build read replies, and send read replies back to delegators */
void* sm_service_reads(void* ctx)
{
    /* allocate a buffer to hold read data before packing
     * into send buffers */
    read_buf = malloc(READ_BUF_SZ);
    if (read_buf == NULL) {
        // TODO: we need a better way to handle this case
        LOGERR("failed to allocate read buffer!");
        sm_rc = (int)UNIFYCR_ERROR_NOMEM;
        return (void*)&sm_rc;
    }

    /* initialize value on how long to wait before processing
     * incoming read requests */
    long bursty_interval = MAX_BURSTY_INTERVAL / 10;

    /* tracks how much data we process in each burst */
    burst_data_sz = 0;

    /* intialize our data structure for holding read requests */
    size_t bytes = MAX_META_PER_SEND * sizeof(send_msg_t);
    service_msgs.msg = (send_msg_t*)malloc(bytes);
    service_msgs.num = 0;
    service_msgs.cap = MAX_META_PER_SEND;

    /* intialize our data structure for holding read tasks */
    bytes = MAX_META_PER_SEND * sizeof(read_task_t);
    read_task_set.read_tasks = (read_task_t*)malloc(bytes);
    read_task_set.num        = 0;
    read_task_set.cap        = MAX_META_PER_SEND;

    /* allocate a list to track pending data read operations */
    pended_reads = arraylist_create();
    if (pended_reads == NULL) {
        sm_rc = (int)UNIFYCR_ERROR_NOMEM;
        return (void*)&sm_rc;
    }

    /* allocate a list to track outstanding sends back to
     * requesting delegators */
    pended_sends = arraylist_create();
    if (pended_sends == NULL) {
        sm_rc = (int)UNIFYCR_ERROR_NOMEM;
        return (void*)&sm_rc;
    }

    /* allocate a list to track pending send operations
     * that need to be initiated back to requesting delegators */
    send_buf_list = arraylist_create();
    if (send_buf_list == NULL) {
        sm_rc = (int)UNIFYCR_ERROR_NOMEM;
        return (void*)&sm_rc;
    }

    /* allocate memory to hold meta data for read replies */
    bytes = glb_size * MAX_NUM_CLIENTS * sizeof(rank_ack_meta_t);
    rank_ack_task.num       = 0;
    rank_ack_task.ack_metas = (rank_ack_meta_t*)malloc(bytes);

    /* initialize each ack_meta structure, keep one for each potential
     * application client
     * (num delegaotrs * max num clients per delegator) */
    int i;
    for (i = 0; i < glb_size * MAX_NUM_CLIENTS; i++) {
        /* get pointer to current structure */
        rank_ack_meta_t* ack_meta = &rank_ack_task.ack_metas[i];

        /* initialize fields */
        ack_meta->ack_list     = NULL;
        ack_meta->rank_id      = -1;
        ack_meta->thrd_id      = -1;
        ack_meta->src_sz       = 0;
        ack_meta->start_cursor = 0;
    }

    /* received message format:
     *   cmd, req_num, a list of read requests */

    /* buffer to hold received msg,
     * since this is large, malloc it instead of declare it on stack
     * (mitigate problems thread stack size limits) */
    char* req_msg_buf = (char*)malloc(REQ_BUF_LEN);

    /* listen and server incoming requests until signaled to exit */
    MPI_Status status;
    int done = 0;
    while (!done) {
        /* post a receive for incoming request */
        MPI_Request request;
        MPI_Irecv(req_msg_buf, REQ_BUF_LEN, MPI_BYTE,
                  MPI_ANY_SOURCE, CLI_DATA_TAG,
                  MPI_COMM_WORLD, &request);

        /* test whether we received anything */
        int irecv_flag = 0;
        int return_code = MPI_Test(&request, &irecv_flag, &status);
        if (return_code != MPI_SUCCESS) {
            sm_rc = (int)UNIFYCR_ERROR_RECV;
            return (void*)&sm_rc;
        }

        /* as long as we keep receiving requests, we'll keep skipping
         * the while loop below (and its sleep) and keep appending
         * items to our read request queue */

        /*
         * keep receiving the read request
         * until the end of a anticipated
         * bursty behavior
         * */
        while (!irecv_flag) {
            /* if we have not received anything, sleep */
            if (bursty_interval > MIN_SLEEP_INTERVAL) {
                usleep(SLEEP_INTERVAL); /* wait an interval */
                wait_time += SLEEP_INTERVAL;
            }

            /* a bursty behavior is considered end when
             * wait time is larger than BURSTY_INTERVAL
             * */
            if ((wait_time >= bursty_interval) ||
                (bursty_interval <= MIN_SLEEP_INTERVAL)) {
                /* if time to wait has expired, and if we have some
                 * queued read requests, do some work */
                if (service_msgs.num > 0) {
                    /* run through list of read requests and generate
                     * read tasks, merge requests for contiguous data
                     * into a single read task */
                    int rc = sm_cluster_reads(&read_task_set,
                                              &service_msgs);
                    if (rc != 0) {
                        sm_rc = rc;
                        return (void*)&sm_rc;
                    }

                    /* execute read tasks, wait for them to complete,
                     * then pack read replies, send to delegators, and
                     * finally wait for sends to complete */
                    rc = sm_read_send_pipe(&read_task_set,
                                           &service_msgs, &rank_ack_task);
                    if (rc != 0) {
                        sm_rc = rc;
                        return (void*)&sm_rc;
                    }

                    /* have processed all read requests and read tasks,
                     * prep them for next message */
                    service_msgs.num  = 0;
                    read_task_set.num = 0;

                    /* determine how long to wait next time based on
                     * how much data we just processed in this burst */
                    if (burst_data_sz >= LARGE_BURSTY_DATA) {
                        /* for large bursts above a threshold,
                         * wait for a fixed amount of time */
                        bursty_interval = MAX_BURSTY_INTERVAL;
                    } else {
                        /* for smaller bursts, set delay proportionally
                         * to burst size we just processed */
                        bursty_interval =
                            (long)((double)burst_data_sz / MIB) *
                            SLEEP_SLICE_PER_UNIT;
                    }

                    /* reset our burst size counter */
                    burst_data_sz = 0;
                }

                /* reset our timer */
                wait_time = 0;
            }

            /* test for receive again, will break while loop
             * if we find something */
            return_code = MPI_Test(&request, &irecv_flag, &status);
            if (return_code != MPI_SUCCESS) {
                sm_rc = (int)UNIFYCR_ERROR_RECV;
                return (void*)&sm_rc;
            }
        }

        /* got a message, reset wait time */
        wait_time = 0;

        /* first value of receive buffer is integer holding command */
        int cmd = *((int*)req_msg_buf);

        /* check whether this is a request for data */
        if (cmd == XFER_COMM_DATA)  {
            /* got a request for data, append read requests in message
             * to our service_msgs list */
            sm_decode_msg(req_msg_buf);
        } else if (cmd == XFER_COMM_EXIT) {
            /* time to exit, free off data structures */
            sm_exit();

            /* set flag to exit */
            done = 1;
        }
    }

    /* free receive buffer */
    free(req_msg_buf);
    req_msg_buf = NULL;

    LOGDBG("thread exiting");

    return (void*)&sm_rc;
}
